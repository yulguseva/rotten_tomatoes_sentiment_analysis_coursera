{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "1e72444b737db4452f185311a1b297363c5ad979"
      },
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nimport keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\nfrom keras.layers import (Input, Dense, Embedding, LSTM, GRU, Bidirectional, \n                        SpatialDropout1D,  GlobalMaxPooling1D, Concatenate, \n                        Conv1D, Dropout, BatchNormalization, Activation)\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam, SGD, Nadam\nfrom keras.models import Model\nfrom keras import backend as K\n\nprint('Keras version', keras.__version__)\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Keras version 2.2.2\n['train.tsv', 'test.tsv', 'sampleSubmission.csv']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "d2a3cb7a22f03f796daa51d9277d4638476e78c6"
      },
      "cell_type": "markdown",
      "source": "## Quick analysis"
    },
    {
      "metadata": {
        "_uuid": "fe9bea8997b071d685f1de945a81c1a859a17eac"
      },
      "cell_type": "markdown",
      "source": "Data is a set of sentences labeled with sentiments from 0 (negative) to 4 (positive). "
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "938728003b1e51e2d00806810de13885bdb11243"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/train.tsv',  sep=\"\\t\")\ntest = pd.read_csv('../input/test.tsv',  sep=\"\\t\")",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "260fc877163753bb35d737dd95b0b55fc33b073f"
      },
      "cell_type": "code",
      "source": "train.head()",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 34,
          "data": {
            "text/plain": "   PhraseId    ...      Sentiment\n0         1    ...              1\n1         2    ...              2\n2         3    ...              2\n3         4    ...              2\n4         5    ...              2\n\n[5 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>A series of escapades demonstrating the adage ...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>A series</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>1</td>\n      <td>A</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>1</td>\n      <td>series</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "ed6ed34a6e3c5f3242e8c2eb63f2e38146ddcce6"
      },
      "cell_type": "markdown",
      "source": "As we can see sentences are divided into phrases to analyse. Sometimes a phrase consists of just a word. Let take a look how the sentence number 10 is represented in the data:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "ca240ee3ab98c360cbd862e01e0d0d9010eb0c24"
      },
      "cell_type": "code",
      "source": "train.loc[train.SentenceId == 10]",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 35,
          "data": {
            "text/plain": "     PhraseId    ...      Sentiment\n259       260    ...              1\n260       261    ...              1\n261       262    ...              0\n262       263    ...              2\n263       264    ...              1\n264       265    ...              0\n265       266    ...              0\n266       267    ...              2\n267       268    ...              2\n268       269    ...              2\n269       270    ...              2\n270       271    ...              2\n\n[12 rows x 4 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PhraseId</th>\n      <th>SentenceId</th>\n      <th>Phrase</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>259</th>\n      <td>260</td>\n      <td>10</td>\n      <td>You could hate it for the same reason .</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>260</th>\n      <td>261</td>\n      <td>10</td>\n      <td>could hate it for the same reason .</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>261</th>\n      <td>262</td>\n      <td>10</td>\n      <td>could hate it for the same reason</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>262</th>\n      <td>263</td>\n      <td>10</td>\n      <td>could</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>263</th>\n      <td>264</td>\n      <td>10</td>\n      <td>hate it for the same reason</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>264</th>\n      <td>265</td>\n      <td>10</td>\n      <td>hate it</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>265</th>\n      <td>266</td>\n      <td>10</td>\n      <td>hate</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>266</th>\n      <td>267</td>\n      <td>10</td>\n      <td>for the same reason</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>267</th>\n      <td>268</td>\n      <td>10</td>\n      <td>the same reason</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>269</td>\n      <td>10</td>\n      <td>same reason</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>269</th>\n      <td>270</td>\n      <td>10</td>\n      <td>same</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>270</th>\n      <td>271</td>\n      <td>10</td>\n      <td>reason</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "07cafd92396357243685fed04994375f80bee3b4"
      },
      "cell_type": "code",
      "source": "print('average phrase length is', train['Phrase'].str.len().mean())\nprint('max phrase length is', train['Phrase'].str.len().max())",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "average phrase length is 40.217224144559786\nmax phrase length is 283\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "b893536320c9c86e3fce976a680fc73816d7f531"
      },
      "cell_type": "markdown",
      "source": "Labels are distributed as follows:"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "024261a1266cffd8419f40e6ba3d08f8c06d0e18"
      },
      "cell_type": "code",
      "source": "train['Sentiment'].value_counts()",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "2    79582\n3    32927\n1    27273\n4     9206\n0     7072\nName: Sentiment, dtype: int64"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "0e5e1d7365f189f5e4213523cba95f61cf8da719"
      },
      "cell_type": "markdown",
      "source": "As we can see most of the phrases are neutral or close to neutral, which makes them more difficult to classify."
    },
    {
      "metadata": {
        "_uuid": "25d2817c00a428a3baccf3b5bc93d78ac98fcb20"
      },
      "cell_type": "markdown",
      "source": "## Preprocessing"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd1fdf74398dd5198be107c3ab83c3bbda5f04cc"
      },
      "cell_type": "code",
      "source": "MAX_LEN = 100\nEMBEDDING_DIM = 300\nMAX_FEATURES = 100000\nRANDOM_STATE = 123\n#GLOVE_DIR = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n\ndef preprocessing(train, test, max_len=MAX_LEN, max_features=MAX_FEATURES, train_size=0.75):\n    \"\"\"\n        https://www.kaggle.com/antmarakis/cnn-baseline-model\n    \"\"\"\n    #lower\n    X = train['Phrase'].apply(lambda x: x.lower())\n    X_test = test['Phrase'].apply(lambda x: x.lower())\n    \n    #tokenizing\n    X = X.values.tolist()\n    X_test = X_test.values.tolist()\n    X_tok = X + X_test\n    tokenizer = Tokenizer(num_words=max_features, filters='')\n    tokenizer.fit_on_texts(X_tok)\n    \n    X = tokenizer.texts_to_sequences(X)\n    X_test = tokenizer.texts_to_sequences(X_test)\n    \n    #add zero padding to the left\n    X = pad_sequences(X, maxlen=max_len)\n    X_test = pad_sequences(X_test, maxlen=max_len)\n    \n    word_index = tokenizer.word_index\n    \n    y = train['Sentiment'].values\n        \n    Y = to_categorical(y)\n    X_train, X_valid, y_train, y_valid = train_test_split(X,\n                                                          Y,\n                                                          train_size=train_size,\n                                                          shuffle=True,\n                                                          random_state=RANDOM_STATE,\n                                                          stratify=y)\n    #loss_weights = [1/5 for _ in range(5)]\n    \n    return X_train, X_valid, y_train, y_valid, X_test, loss_weights, word_index",
      "execution_count": 40,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4219bfd9fe249f983748140c4d841a8a62a31a76"
      },
      "cell_type": "markdown",
      "source": "## Models"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a6e9c8e3990acaf6ee06ca26b1c09aee4214d47d"
      },
      "cell_type": "code",
      "source": "from keras.layers import Input, Dense, Embedding, Flatten\nfrom keras.layers import SpatialDropout1D\nfrom keras.layers.convolutional import Conv1D, MaxPooling1D\nfrom keras.models import Sequential\n\ndef make_model_cnn ():\n    model = Sequential()\n\n    # Input / Embdedding\n    model.add(Embedding(MAX_FEATURES, 150, input_length=MAX_LEN))\n\n    # CNN\n    model.add(SpatialDropout1D(0.2))\n\n    model.add(Conv1D(64, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n\n    model.add(Conv1D(128, kernel_size=3, padding='same', activation='relu'))\n    model.add(MaxPooling1D(pool_size=2))\n\n    model.add(Flatten())\n\n    # Output layer\n    model.add(Dense(5, activation='sigmoid'))\n    return model",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "8a053228ee3dc3537321a661b7090a9491b5a636"
      },
      "cell_type": "code",
      "source": "#s = reset_tf_session()  # clear default graph\nmodel = make_model_cnn()\nmodel.summary()",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_3 (Embedding)      (None, 100, 150)          15000000  \n_________________________________________________________________\nspatial_dropout1d_3 (Spatial (None, 100, 150)          0         \n_________________________________________________________________\nconv1d_5 (Conv1D)            (None, 100, 64)           28864     \n_________________________________________________________________\nmax_pooling1d_5 (MaxPooling1 (None, 50, 64)            0         \n_________________________________________________________________\nconv1d_6 (Conv1D)            (None, 50, 128)           24704     \n_________________________________________________________________\nmax_pooling1d_6 (MaxPooling1 (None, 25, 128)           0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 3200)              0         \n_________________________________________________________________\ndense_3 (Dense)              (None, 5)                 16005     \n=================================================================\nTotal params: 15,069,573\nTrainable params: 15,069,573\nNon-trainable params: 0\n_________________________________________________________________\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "79a293eddc3a9be6e025d02f117c0c992f881bab"
      },
      "cell_type": "code",
      "source": "MAX_LEN = 100\nEMBEDDING_DIM = 300\nMAX_FEATURES = 100000\nRANDOM_STATE = 123\nEPOCHS = 4\nBATCH_SIZE = 64",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e7d0140cab195ad4d2c514b560280d77952e3ed9"
      },
      "cell_type": "code",
      "source": "X_train, X_valid, y_train, y_valid, X_test, loss_weights, word_index = preprocessing(train, test)",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2069: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n  FutureWarning)\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "167faac6823df5433e527bab55938a066c6209f6"
      },
      "cell_type": "code",
      "source": "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa2b56feb27f071c3dd4b8ccce7b9687f8ce2460"
      },
      "cell_type": "code",
      "source": "sub = pd.read_csv('../input/sampleSubmission.csv')\n\nsub['Sentiment'] = model.predict_classes(test_X, batch_size=batch_size, verbose=1)\nsub.to_csv('sub_cnn.csv', index=False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "collapsed": true,
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}